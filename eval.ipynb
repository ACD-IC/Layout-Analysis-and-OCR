{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a5061c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best model weights from: models/ladas-1280-l.pt\n",
      "\n",
      "Running unbiased validation on the TEST set...\n",
      "Ultralytics 8.3.205  Python-3.11.5 torch-2.2.2 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "YOLO11l summary (fused): 190 layers, 25,307,068 parameters, 0 gradients, 86.7 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 493.182.3 MB/s, size: 295.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\lucia\\Documents\\GitHub\\Layout-Analysis-and-OCR\\RIPA-ft\\test\\labels.cache... 86 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 86/86 84.8Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 0.9it/s 6.5s0.8s\n",
      "                   all         86        969      0.191     0.0809     0.0724     0.0456\n",
      "     AdvertisementZone          4          4          1          0          0          0\n",
      "DigitizationArtefactZone         35         82          0          0          0          0\n",
      "            FigureZone         40         49          0          0          0          0\n",
      "    FigureZone-FigDesc         10         12          0          0          0          0\n",
      "       FigureZone-Head          2          4          1          0          0          0\n",
      "           GraphicZone         12         19          0          0    0.00284    0.00255\n",
      "GraphicZone-Decoration          1          1          0          0          0          0\n",
      "   GraphicZone-FigDesc          4          4     0.0888       0.25     0.0941     0.0713\n",
      "      GraphicZone-Head         35         52          0          0     0.0119    0.00992\n",
      "      GraphicZone-Part          3         18          0          0          0          0\n",
      "GraphicZone-TextualContent         43         84          0          0     0.0125    0.00862\n",
      "    MainZone-Continued          8         16     0.0334      0.125     0.0318     0.0257\n",
      "         MainZone-Date          1          1          0          0          0          0\n",
      "        MainZone-Entry         18         23          0          0     0.0135    0.00993\n",
      "         MainZone-Form         55        241          1          0          0          0\n",
      "         MainZone-Head          4          4          0          0    0.00667    0.00434\n",
      "           MainZone-Lg         26         83      0.246     0.0482     0.0718      0.045\n",
      "        MainZone-Other          6         27     0.0652      0.111      0.021     0.0132\n",
      "            MainZone-P          5          8          0          0    0.00229    0.00186\n",
      "    MainZone-Signature         67         88      0.032     0.0114     0.0215     0.0164\n",
      "           MainZone-Sp         42         55          0          0    0.00298    0.00194\n",
      "MarginTextZone-ManuscriptAddendum         60         74     0.0263     0.0135      0.026     0.0193\n",
      "  MarginTextZone-Notes          5          5          0          0    0.00236    0.00212\n",
      "         NumberingZone          1          1          0          0          0          0\n",
      "         TitlePageZone          3          3      0.745          1       0.83      0.423\n",
      "   TitlePageZone-Index          2         11      0.726      0.545      0.732      0.529\n",
      "Speed: 0.8ms preprocess, 24.6ms inference, 0.0ms loss, 8.3ms postprocess per image\n",
      "Saving C:\\Users\\lucia\\Documents\\GitHub\\Layout-Analysis-and-OCR\\runs\\detect\\val8\\predictions.json...\n",
      "Results saved to \u001b[1mC:\\Users\\lucia\\Documents\\GitHub\\Layout-Analysis-and-OCR\\runs\\detect\\val8\u001b[0m\n",
      "\n",
      "--- TEST SET RESULTS ---\n",
      "mAP@50 (Test Set): 0.0724\n",
      "mAP@50-95 (Test Set): 0.0456\n",
      "Precision (Test Set): 0.1909\n",
      "Recall (Test Set): 0.0809\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# --- 1. DEFINE PATHS ---\n",
    "# CRITICAL: This should point to the BEST model file saved from your previous training run.\n",
    "# Ultralytics saves this automatically in your run directory.\n",
    "#BEST_WEIGHTS_PATH = 'my_finetune_project/run_ladas_1280_l_v14/weights/best.pt'\n",
    "BEST_WEIGHTS_PATH = 'models/ladas-1280-l.pt'\n",
    "# CRITICAL: Path to your dataset configuration file (the one used for training).\n",
    "# This file MUST have a 'test:' path defined for this to work correctly.\n",
    "DATA_YAML_PATH = 'RIPA-ft/data.yaml'\n",
    "\n",
    "# --- 2. LOAD THE BEST MODEL ---\n",
    "# Load the model with the highest performance from the training run\n",
    "print(f\"Loading best model weights from: {BEST_WEIGHTS_PATH}\")\n",
    "model = YOLO(BEST_WEIGHTS_PATH)\n",
    "\n",
    "# --- 3. RUN VALIDATION ON THE TEST SET ---\n",
    "print(\"\\nRunning unbiased validation on the TEST set...\")\n",
    "\n",
    "# The model.val() method runs the evaluation logic.\n",
    "# The 'split=\"test\"' argument specifically instructs Ultralytics to use the \n",
    "# directory defined under the 'test:' key in the DATA_YAML_PATH file.\n",
    "metrics = model.val(\n",
    "    data=DATA_YAML_PATH,     # The dataset configuration file\n",
    "    imgsz=640,               # Should match the image size used during training\n",
    "    split='test',            # CRITICAL: Forces evaluation on the data specified by the 'test:' path\n",
    "    save_json=True           # Optional: Save metrics in a JSON file for easy processing\n",
    ")\n",
    "\n",
    "# --- 4. EXTRACT AND DISPLAY KEY METRICS ---\n",
    "print(\"\\n--- TEST SET RESULTS ---\")\n",
    "\n",
    "# Access the dictionary of results\n",
    "results_dict = metrics.results_dict\n",
    "\n",
    "# Mean Average Precision (mAP)\n",
    "# mAP50 is common, mAP50-95 is more stringent (average across multiple IoU thresholds)\n",
    "mAP50 = results_dict['metrics/mAP50(B)']\n",
    "mAP50_95 = results_dict['metrics/mAP50-95(B)']\n",
    "\n",
    "print(f\"mAP@50 (Test Set): {mAP50:.4f}\")\n",
    "print(f\"mAP@50-95 (Test Set): {mAP50_95:.4f}\")\n",
    "print(f\"Precision (Test Set): {results_dict['metrics/precision(B)']:.4f}\")\n",
    "print(f\"Recall (Test Set): {results_dict['metrics/recall(B)']:.4f}\")\n",
    "\n",
    "# The full results, curves, and confusion matrix plots are saved to the \n",
    "# 'runs/detect/val' directory by default.\n",
    "#print(f\"\\nDetailed metrics saved to: {model.validator.save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "565c3e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "def restructure_flat_output(flat_input_dir: str, structured_output_dir: str):\n",
    "    \"\"\"\n",
    "    Restructures a flat directory of YOLO outputs into a nested structure.\n",
    "\n",
    "    Assumes flat_input_dir contains files like:\n",
    "        - 'BookName_1.txt'\n",
    "        - 'BookName_1.png'\n",
    "        - 'Another_Book_10.txt'\n",
    "        - 'Another_Book_10.png'\n",
    "\n",
    "    Will create a structured_output_dir like:\n",
    "        - 'BookName/txt/page_0001.txt'\n",
    "        - 'BookName/png/page_0001.png'\n",
    "        - 'Another_Book/txt/page_0010.txt'\n",
    "        - 'Another_Book/png/page_0010.png'\n",
    "\n",
    "    Args:\n",
    "        flat_input_dir (str): The path to the existing flat output directory.\n",
    "        structured_output_dir (str): The path to the new root directory for the structured output.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Scanning directory: {flat_input_dir}\")\n",
    "    print(f\"Output will be saved to: {structured_output_dir}\")\n",
    "\n",
    "    # Find all files in the flat directory\n",
    "    file_paths = glob.glob(os.path.join(flat_input_dir, '*.*'))\n",
    "    \n",
    "    if not file_paths:\n",
    "        print(\"No files found to process.\")\n",
    "        return\n",
    "\n",
    "    # Regex to safely parse \"Book_Name_with_underscores_page_123.txt\"\n",
    "    # It captures the book name (non-greedy) and the page number at the end\n",
    "    # This matches the f\"{book_name}_page_{page_number_int}\" format\n",
    "    filename_pattern = re.compile(r'^(.*?)_page_(\\d+)(\\.(?:png|jpg|jpeg|txt))$', re.IGNORECASE)\n",
    "\n",
    "    moved_files_count = 0\n",
    "    skipped_files = []\n",
    "\n",
    "    for old_file_path in tqdm(file_paths, desc=\"Restructuring files\"):\n",
    "        filename = os.path.basename(old_file_path)\n",
    "        \n",
    "        match = filename_pattern.match(filename)\n",
    "        \n",
    "        if not match:\n",
    "            skipped_files.append(filename)\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # --- 1. Parse Filename ---\n",
    "            book_name = match.group(1)\n",
    "            page_number_str = match.group(2)\n",
    "            extension = match.group(3) # e.g., \".png\"\n",
    "            \n",
    "            page_number_int = int(page_number_str)\n",
    "            \n",
    "            # --- 2. Determine New Structure ---\n",
    "            \n",
    "            # Recreate the \"page_0001\" format\n",
    "            new_file_basename = f\"page_{page_number_int:04d}{extension}\"\n",
    "            \n",
    "            # Determine subdirectory ('txt' or 'png')\n",
    "            if extension.lower() == '.txt':\n",
    "                file_type_dir = 'txt'\n",
    "            else:\n",
    "                file_type_dir = 'png' # Group all images under 'png'\n",
    "                \n",
    "            # --- 3. Create Target Path and Move File ---\n",
    "            \n",
    "            # Create the full target directory: output/BookName/txt\n",
    "            target_dir = os.path.join(structured_output_dir, book_name, file_type_dir)\n",
    "            os.makedirs(target_dir, exist_ok=True)\n",
    "            \n",
    "            # Create the final file path: output/BookName/txt/page_0001.txt\n",
    "            new_file_path = os.path.join(target_dir, new_file_basename)\n",
    "            \n",
    "            # Move the file\n",
    "            shutil.move(old_file_path, new_file_path)\n",
    "            moved_files_count += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {filename}: {e}\")\n",
    "            skipped_files.append(filename)\n",
    "\n",
    "    # --- 4. Final Report ---\n",
    "    print(\"\\nRestructuring complete.\")\n",
    "    print(f\"Successfully moved {moved_files_count} files.\")\n",
    "    \n",
    "    if skipped_files:\n",
    "        print(f\"\\nSkipped {len(skipped_files)} files (unrecognized format):\")\n",
    "        for f in skipped_files[:10]: # Print a sample\n",
    "            print(f\"  - {f}\")\n",
    "        if len(skipped_files) > 10:\n",
    "            print(f\"  ... and {len(skipped_files) - 10} more.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b09c41c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning directory: inference_output_batch_all\n",
      "Output will be saved to: structured_inference_output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restructuring files: 100%|██████████| 36784/36784 [01:04<00:00, 567.09it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Restructuring complete.\n",
      "Successfully moved 36784 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "restructure_flat_output(\"inference_output_batch_all\", \"structured_inference_output\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
